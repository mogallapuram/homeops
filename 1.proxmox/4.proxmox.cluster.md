# Proxmox Cluster Setup Documentation

## Cluster Information

**Cluster Name:** mycluster  
**Creation Date:** November 18, 2025  
**Number of Nodes:** 2

## Node Details

| Node Name | IP Address    | Role   | Status |
|-----------|---------------|--------|--------|
| node1     | 10.10.10.200  | Master | Online |
| node2     | 10.10.11.200  | Member | Online |

## Cluster Setup Summary

### What Was Done

1. **Created Cluster on node1**
   ```bash
   pvecm create mycluster
   ```

2. **Joined node2 to Cluster**
   ```bash
   pvecm add 10.10.10.200
   ```

3. **Verified Cluster Status**
   ```bash
   pvecm status
   pvecm nodes
   ```

## Important Notes

### ⚠️ Quorum Considerations

With only 2 nodes, the cluster does **not** have proper quorum for high availability:
- If one node fails, the remaining node will lose quorum
- VMs will not automatically migrate or restart on failure
- Manual intervention may be required

**Recommended Solutions:**
- Add a 3rd node for proper quorum (ideal)
- Configure a QDevice (Quorum Device) on a separate machine
- Accept manual intervention in case of node failure

### Network Configuration

- **Node1 Network:** 10.10.10.0/24
- **Node2 Network:** 10.10.11.0/24
- **Cluster Traffic:** Uses node management IPs
- **Recommendation:** Consider dedicating a separate network interface for cluster communication (corosync)

### Required Ports

Ensure these ports are open between nodes:
- **22** - SSH
- **5404-5405** - Corosync (cluster communication)
- **8006** - Proxmox Web UI
- **3128** - Proxmox API proxy

## Common Management Commands

### Check Cluster Status
```bash
pvecm status
```

### List Cluster Nodes
```bash
pvecm nodes
```

### View Expected Votes
```bash
pvecm expected 1
```
Use this if a node fails and you need to force quorum on the remaining node.

### Check Corosync Status
```bash
systemctl status corosync
systemctl status pve-cluster
```

### View Cluster Configuration
```bash
cat /etc/pve/corosync.conf
```

## Backup and Recovery

### Backup Configuration
- Configuration is automatically stored in `/etc/pve/`
- This is a cluster-wide filesystem (pmxcfs)
- Regular backups recommended

### Node Removal (if needed)
```bash
# From another node in the cluster
pvecm delnode nodename
```

## Next Steps / Recommendations

### 1. Configure Shared Storage
For VM migration and HA, configure shared storage:
- **NFS** - Network File System
- **Ceph** - Distributed storage (requires 3+ nodes)
- **iSCSI** - Block-level storage
- **GlusterFS** - Distributed filesystem

### 2. Set Up High Availability (Optional)
```bash
# Install HA manager
apt update
apt install pve-ha-manager

# Configure HA groups and resources via Web UI
```

### 3. Configure Fencing (Recommended)
Set up fencing mechanisms to prevent split-brain scenarios:
- IPMI/BMC fencing
- Network watchdog
- Manual fencing policies

### 4. Network Redundancy
- Configure bonding/LACP for network redundancy
- Separate cluster network from VM/storage networks
- Use multiple network links for corosync

### 5. Monitoring
- Set up email notifications for cluster events
- Monitor cluster health regularly
- Configure alerting for quorum loss

## Troubleshooting

### Cluster Service Issues
```bash
# Restart cluster services
systemctl restart pve-cluster
systemctl restart corosync

# Check logs
journalctl -u pve-cluster -f
journalctl -u corosync -f
```

### Quorum Lost
```bash
# Check current quorum status
pvecm status

# Force quorum on remaining node (emergency only)
pvecm expected 1
```

### Node Communication Issues
```bash
# Test connectivity
ping 10.10.10.200
ping 10.10.11.200

# Check firewall
iptables -L

# Verify hostname resolution
cat /etc/hosts
```

## Access Information

### Web Interface
- **Node1:** https://10.10.10.200:8006
- **Node2:** https://10.10.11.200:8006

### SSH Access
```bash
ssh root@10.10.10.200  # node1
ssh root@10.10.11.200  # node2
```

## Maintenance Schedule

- [ ] Regular backup verification
- [ ] Monthly cluster health checks
- [ ] Quarterly firmware updates
- [ ] Review and update this documentation

## Support Resources

- **Proxmox Documentation:** https://pve.proxmox.com/wiki/Main_Page
- **Proxmox Forum:** https://forum.proxmox.com/
- **Cluster Management:** https://pve.proxmox.com/wiki/Cluster_Manager

---

**Author:** Ramakrishna Mogallapu  
**Project:** HomeOps — Building a Fully Automated K3s Homelab  
**Proxmox Version:** 9.x (Trixie)  
**Revision:** 1
**Date:** 18 Nov 2025